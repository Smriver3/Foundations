
---
title: "Transaction Analytics Spring 2020 Exercise  \n Section I *(Foundations for Bayesian Analysis)*"
output: pdf_document
---
```{r setup, include=FALSE, echo = F}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, comment=NA, message=F, warning=F, fig.width=4, fig.height=3, fig.align="center"}

library(DBI)

# con2 removed for security

locationString = "C:/Users/ellen/Documents/UH/Spring 2020/DA2/Section 1/Review"

library(kableExtra)

setwd("C:/Users/ellen/Documents/UH/Spring 2020/DA2/Section 1/Review")

'%!in%' <- function(x,y)!('%in%'(x,y))

```

Load the following libraries:

```{r, echo = TRUE, comment=NA, message=F, warning=F, fig.width=4, fig.height=3, fig.align="center"}

library(tidyverse)
library(caret)
library(lubridate)
library(DMwR)

```

## Introduction and Motivation

The following scenario tests your competencies in delivering the explanatory models necessary to test process controls and the transactions they create. These competencies are already a critical in Assurance and Consulting, but they will become more so in the near future, for many reasons including:

1. **Financial Assurance and Risk Management** is being disrupted by migration or ERP processes to RPA, AI, and other Intelligent Platforms *(e.g., Blockchain, IoT)*. ERP hosts *(and controls)* a smaller and smaller proportion of enterprise transactions every day, and the new platforms provide nowhere near the level of control for Risk Management.
2. **Consulting** delivery is also being disrupted as the implementation of these platforms drives growth. The emergent and ambiguous nature of these deliverables, and the ability to interpret **Quality Assurance** metrics in probabilistic terms is creating serious challenges.  
The following exercise is a very basic scenario that addresses foundations for these competencies.  

## Scenario and Deliverables:

The year is 2014 and you've been assigned to help with testing of controls in preparation for an the current year Assurance engagement. Your client is DemoDreams consulting. You want to test the billing control process which can be outlined as follows:  

1. Employees enter the Date, ProjectID, CostCode, and Hours into the Billing System, and BillingAmt is calculated based on their StdRate *(Employee Table)*.  
  
2. The Engagement Manager approves, and can make adjustments to either the Hours or the BilledAmt *(so StdRate x Hours may not equal BilledAmt - StdRate does not show on Invoices)*. If an adjustment is made, the EM *should* choose approval code '110', as transactions with a '110' are reviewed by the Controller, and if approved, a notation made in the comments field: 'AC' followed by the year *(so transactions with 'AC2012', 'AC2013' are approved adjustments)*.  
  
You need to design a model to test if this process is in compliance with procedure.  

1. Create a Logistic Regression model that tests transactional compliance based on 2012 data and tested on 2013 data. Your deliverables are specifically:

>  a. Vector of model parameters
>  b. Model.Matrix of Data with intercept and indicator variables
>  c. Probabilities stored in a Prob column in the test data.  

2. Report confusion matrix results.  

\pagebreak

3. Create a plot that shows your models Probabilities vs Hours:  

>  a. Probabilities on y axis, with Hours on x.
>  b. Color groups for StdRates.
>  c. Data Points in black for compliant transaction classes and in color of non-compliant classes.  

## Guidance and Hints:

* [ERP].[Billing].[AprCode] has the approval codes for transactions. Specifically, we just want to pull all the [AprCode] = '110' transactions. Also, only include transactions with [CostCode].[CostCode] < '900', as all cost codes greater than 900 are non-billable projects. Next, you'll want to eliminate transactions where the comments have a 'AC2012', or 'AC2013'. We're only interested in testing the *Marginal Population*, that is: the 110 transactions that have not been approved $P(Exception \mid Non-Approved 110 Transactions)$.  You might find the following function helpful:  

>'%!in%' <- function(x,y)!('%in%'(x,y))  
>This is nothing fancy, but can save you a little work if you apply it like so:  
>Billing = Billing %>% filter(Comments %!in% c('AC2012', 'AC2013'))   

* Remember, you'll need to create an Exception column in the test set, and set it to 1 if StdRate x Hours != BilledAmt and test against that.  

* Separate training and test sets *(2012 and 2013 respectively)*.  

* Simplify your datasets - you'll only need to select Date, StdRate, Hours, Exception before breaking into test/training and you can drop Date after the split - make your life as simple as possible!    

* You'll need to use SMOTE , as the data is very unbalanced. *Don't forget that smote only deals with numeric or factors*. Also, remember that the perc.over parameter is the amount you want to increase your minority dataset - in this case, **A lot**, like maybe 5,000%. And the perc.under parameter is the amount of balance with the majority set you want - in this case you want it even, like maybe 100%.

* Pull the parameters out glm and store in a vector. Use model.matrix to transform the 2013 data for testing. Plug the parameter vector and model.matrix into the logistic formula to generate your probabilities. Then, break your classes *(0,1)* at the .5. probability point. Now you can run your results through a confusion matrix and plot probabilities *(all shown below)*

***

### Data Sources

Review the following ERD from the Accounting Database / ERP Schema


![ERP.Billing ERD)](C:/Users/ellen/Documents/Pictures/Billing_ERD.png){ width=75% }

Suggested Select:  

[ERP].[Billing].[TransID]  
[ERP].[Billing].[Date]  
[ERP].[Billing].[AprCode]  
[ERP].[Billing].[EmployeeID]   
[ERP].[Employee].[StdRate]  
[ERP].[Employee].[EmployeeName]  
[ERP].[Billing].[Hours]  
[ERP].[CostCode].[CostCode]  
[ERP].[CostCode].[Description]  
[ERP].[Billing].[BilledAmt]  
[ERP].[Billing].[Comments]  


### Confusion Matrix:

Output from the confusion matrix should be similar to:

```{r, message=F, warning=F, fig.width=6, fig.height=6, fig.align="center", eval=T, echo=F}
Billing <-  dbGetQuery(con2,"
SELECT 
       [ERP].[Billing].[TransID]
      ,[ERP].[Billing].[Date]
      ,[ERP].[Billing].[AprCode]
      ,[ERP].[Billing].[EmployeeID] 
      ,[ERP].[Employee].[StdRate]
      ,[ERP].[Employee].[EmployeeName]
      ,[ERP].[Billing].[Hours]
      ,[ERP].[CostCode].[CostCode]
      ,[ERP].[CostCode].[Description]
      ,[ERP].[Billing].[BilledAmt]
      ,[ERP].[Billing].[Comments]
  FROM [ERP].[Billing]
  INNER JOIN
  [ERP].[CostCode]
  ON
  [ERP].[Billing].[CostCode] = [ERP].[CostCode].[CostCode]
  INNER JOIN
  [ERP].[Employee]
  ON
  [ERP].[Billing].[EmployeeID] = [ERP].[Employee].[EmployeeID]
  WHERE
  [ERP].[Billing].[Date] BETWEEN '2012-01-01' AND '2013-12-31'
  AND
  [ERP].[CostCode].[CostCode] < '900'
  AND
  [ERP].[Billing].[AprCode] = '110'
")

Billing = Billing %>% filter(Comments %!in% c('AC2012', 'AC2013'))

Billing = Billing %>% mutate(Exception = ifelse(((Hours * StdRate) - BilledAmt != 0), 1, 0))
Billing = select(Billing, TransID,  Date, StdRate, Hours, Exception)

Billing$Exception = as.factor(Billing$Exception)
Billing$StdRate = as.factor(Billing$StdRate)

Billing$Date = ymd(Billing$Date)
Billing$Yr = year(Billing$Date)
Billing2012 = filter(Billing, Yr == '2012')
Billing2013 = filter(Billing, Yr == '2013')

B12 = select(Billing2012, Exception, StdRate, Hours)
smoteData <- SMOTE(Exception ~ ., data = B12, perc.over = 2000, perc.under = 100) 

glm.fit <- glm(Exception ~ StdRate + Hours, data = smoteData, family = binomial)

ModMatrix = model.matrix(Exception ~ StdRate + Hours, data = Billing2013)
beta = as.numeric(glm.fit$coefficients)
Billing2013$Prob <- exp(t(beta%*%t(ModMatrix)))/(1+exp(t(beta%*%t(ModMatrix))))
Billing2013 = Billing2013 %>% mutate (Class = if_else(Prob < .5, 0, 1)) 
confusionMatrix(factor(Billing2013$Class), factor(Billing2013$Exception), positive = "1")

```

### Probability Plot:

The probabilities generated from the logistic formula can be plotted v Hours, with color = factor(StdRate). You should be able to visualize how the probability of an exception changes with different billing levels and where the exception points change on the probability curves - connect with geom_line():

```{r, message=F, warning=F, fig.width=4, fig.height=3, fig.align="center", eval=T, echo=F}

ggplot(Billing2013, aes(x=Hours, y=Prob, color = factor(StdRate))) + 
  geom_point(data = filter(Billing2013, Exception != 1), color = "black") +
  geom_line() +
  geom_point(data = filter(Billing2013, Exception == 1)) +
  theme(panel.background = element_rect(fill = "white")) 

```

Based on what you have learned, where would you recommend focusing substantive testing?



